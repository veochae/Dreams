{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/veochae/opt/anaconda3/envs/ANLY501/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/veochae/Desktop/Dreams/data cleaning\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import nltk\n",
    "from datetime import datetime, date\n",
    "import sys\n",
    "\n",
    "#check for current working path, and set the working path to the data folder\n",
    "\n",
    "print(Path.cwd())\n",
    "os.chdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./raw_data.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>I think it was my grandad</td>\n",
       "      <td>So, I  had this dream when I was a kid , age 9...</td>\n",
       "      <td>2023-02-05 21:13:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>A nondescript blurry figure standing over me</td>\n",
       "      <td>Im laying in bed face up where a blurry unknow...</td>\n",
       "      <td>2023-02-05 20:58:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>Dream my family hated me because I am disabled</td>\n",
       "      <td>I had this dream 3 nights ago and it still has...</td>\n",
       "      <td>2023-02-05 20:29:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>Furry exhibitionists on a sidewalk</td>\n",
       "      <td>Oh my god it was awful.\\n\\nSo awful. \\n\\nI was...</td>\n",
       "      <td>2023-02-05 20:29:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>I had deja vu 3 times last week</td>\n",
       "      <td>For context: I don’t dream often but when I do...</td>\n",
       "      <td>2023-02-05 20:02:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>Several months ago I had reoccurring dreams ab...</td>\n",
       "      <td>&amp;amp;#x200B;\\n\\nhttps://preview.redd.it/8zi4ej...</td>\n",
       "      <td>2023-01-27 06:43:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>Fudge Shop Dream</td>\n",
       "      <td>Today I dreamed about being at a large fudge s...</td>\n",
       "      <td>2023-01-27 06:18:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>I killed a man that travelled through time</td>\n",
       "      <td>I was running around in a mansion trying to se...</td>\n",
       "      <td>2023-01-27 05:53:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>Recurring dream</td>\n",
       "      <td>As the title says. It's a recurring dream, but...</td>\n",
       "      <td>2023-01-27 05:47:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Dreams</td>\n",
       "      <td>I dreamt I am rooting for our Putinist leader</td>\n",
       "      <td>I felt a bit of shame as I agreed in the dream...</td>\n",
       "      <td>2023-01-27 05:45:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit                                              title  \\\n",
       "0      Dreams                          I think it was my grandad   \n",
       "1      Dreams       A nondescript blurry figure standing over me   \n",
       "2      Dreams     Dream my family hated me because I am disabled   \n",
       "3      Dreams                 Furry exhibitionists on a sidewalk   \n",
       "5      Dreams                    I had deja vu 3 times last week   \n",
       "..        ...                                                ...   \n",
       "982    Dreams  Several months ago I had reoccurring dreams ab...   \n",
       "984    Dreams                                   Fudge Shop Dream   \n",
       "985    Dreams         I killed a man that travelled through time   \n",
       "986    Dreams                                    Recurring dream   \n",
       "987    Dreams      I dreamt I am rooting for our Putinist leader   \n",
       "\n",
       "                                                  text                date  \n",
       "0    So, I  had this dream when I was a kid , age 9... 2023-02-05 21:13:41  \n",
       "1    Im laying in bed face up where a blurry unknow... 2023-02-05 20:58:10  \n",
       "2    I had this dream 3 nights ago and it still has... 2023-02-05 20:29:39  \n",
       "3    Oh my god it was awful.\\n\\nSo awful. \\n\\nI was... 2023-02-05 20:29:22  \n",
       "5    For context: I don’t dream often but when I do... 2023-02-05 20:02:04  \n",
       "..                                                 ...                 ...  \n",
       "982  &amp;#x200B;\\n\\nhttps://preview.redd.it/8zi4ej... 2023-01-27 06:43:28  \n",
       "984  Today I dreamed about being at a large fudge s... 2023-01-27 06:18:24  \n",
       "985  I was running around in a mansion trying to se... 2023-01-27 05:53:28  \n",
       "986  As the title says. It's a recurring dream, but... 2023-01-27 05:47:53  \n",
       "987  I felt a bit of shame as I agreed in the dream... 2023-01-27 05:45:35  \n",
       "\n",
       "[900 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = [datetime.fromtimestamp(time) for time in df['date']]\n",
    "df= df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      So, I  had this dream when I was a kid , age 9...\n",
       "1      Im laying in bed face up where a blurry unknow...\n",
       "2      I had this dream 3 nights ago and it still has...\n",
       "3      Oh my god it was awful.\\n\\nSo awful. \\n\\nI was...\n",
       "5      For context: I don’t dream often but when I do...\n",
       "                             ...                        \n",
       "982    &amp;#x200B;\\n\\nhttps://preview.redd.it/8zi4ej...\n",
       "984    Today I dreamed about being at a large fudge s...\n",
       "985    I was running around in a mansion trying to se...\n",
       "986    As the title says. It's a recurring dream, but...\n",
       "987    I felt a bit of shame as I agreed in the dream...\n",
       "Name: text, Length: 900, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/veochae/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/veochae/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean(text):\n",
    "     # text = text.replace(',Äô', '\\'')\n",
    "     text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "     text = re.sub(' +', ' ', text)\n",
    "     text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "     text = re.sub('\\[.*?\\]', '', text)\n",
    "     text = re.sub('\\n', '', text)\n",
    "     text = re.sub('\\w*\\d\\w*', '', text)\n",
    "     text = re.sub('<.*?>+', '', text)\n",
    "     text = re.sub('(?<=:)\\w-', '', text)\n",
    "     text = re.sub('(?<=@)\\w+', '', text)\n",
    "     text = re.sub('@', '', text)\n",
    "     text = re.sub(':', '', text)\n",
    "     text = re.sub('RT', '', text)\n",
    "     text = re.sub('_', \"\", text)\n",
    "     text = re.sub(\"&amp;#;\", \"\", text)\n",
    "     text = text.strip()\n",
    "     return text\n",
    "\n",
    "def tokenization(text):\n",
    "     text = re.split('\\W+', text)\n",
    "     return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "     text = [word for word in text if word not in stopword]\n",
    "     return text\n",
    "\n",
    "def stemming1(text):\n",
    "     text = [ps.stem(word) for word in text]\n",
    "     return text \n",
    "\n",
    "def stemming2(text):\n",
    "     text = [s_stemmer.stem(word) for word in text]\n",
    "     return text\n",
    "\n",
    "def lemmatizer(text):\n",
    "     text = [wn.lemmatize(word) for word in text]\n",
    "     return text\n",
    "\n",
    "def vectorization(li):\n",
    "    vectorizer = CountVectorizer()   \n",
    "    Xs = vectorizer.fit_transform(li)   \n",
    "    X = np.array(Xs.todense())\n",
    "    \n",
    "    return X\n",
    "\n",
    "def get_column_name(li):\n",
    "     vectorizer = CountVectorizer()   \n",
    "     Xs = vectorizer.fit_transform(li)   \n",
    "     col_names=vectorizer.get_feature_names_out()\n",
    "     col_names = list(col_names)\n",
    "\n",
    "     return col_names\n",
    "\n",
    "def extract_array(df):\n",
    "     clean_text = df['text'].apply(lambda x:clean(x))\n",
    "     tokenized = clean_text.apply(lambda x: tokenization(x.lower()))\n",
    "     clean_text = clean_text = tokenized.apply(lambda x: \" \".join(x))\n",
    "     print(\"Complete: text cleaning\")\n",
    "     print(\"Complete: tokenization\")\n",
    "     x_stopwords = tokenized.apply(lambda x: remove_stopwords(x))\n",
    "     print(\"Complete: stopwords removed\")\n",
    "     stem = x_stopwords.apply(lambda x: stemming1(x))\n",
    "     print(\"Complete: stemming 1\")\n",
    "     stem = stem.apply(lambda x: stemming2(x))\n",
    "     print(\"Complete: stemming 2\")\n",
    "     lemmatized = stem.apply(lambda x: lemmatizer(x))\n",
    "     print(\"Complete: lemmatization\")\n",
    "     complete = lemmatized.apply(lambda x: \" \".join(x))\n",
    "     mapx = vectorization(complete)\n",
    "     name = get_column_name(complete)\n",
    "     mapx = pd.DataFrame(mapx, columns = name)\n",
    "     mapx.columns = name\n",
    "     print(\"Complete: vectorization\")\n",
    "     print(\"All Done!\")\n",
    "\n",
    "     return clean_text, tokenized, x_stopwords, stem, lemmatized, complete, mapx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: text cleaning\n",
      "Complete: tokenization\n",
      "Complete: stopwords removed\n",
      "Complete: stemming 1\n",
      "Complete: stemming 2\n",
      "Complete: lemmatization\n",
      "Complete: vectorization\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "clean_text, tokenized, x_stopwords, stem, lemmatized, complete, corpus = extract_array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['clean_text', 'tokenized', 'x_stopwords', 'stem', 'lemmatized', 'complete', 'corpus']\n",
    "\n",
    "for title in titles:\n",
    "    vars()[title].to_csv(f'./cleaned data/{title}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ANLY501')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e871aec5cdce359f50730c2f4a4c8102d3246dd2d9815cdf4f3c7213e8de692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
